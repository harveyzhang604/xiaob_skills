#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ’ Profit Hunter LITE - è½»é‡çº§å¿«é€Ÿç‰ˆ
=====================================

èåˆ Yuanbao Skills çš„ä¼˜ç‚¹ï¼š
1. âœ… DuckDuckGo SERP åˆ†æï¼ˆé¿å… Google é™é¢‘ï¼‰
2. âœ… åŠ æƒæ„å›¾è¯„åˆ†ç³»ç»Ÿï¼ˆç—›ç‚¹+3ï¼Œå·¥å…·+2ï¼Œå¯¹æ¯”+2ï¼‰
3. âœ… GPTs Benchmark åŸºå‡†å¯¹æ¯”
4. âœ… ç®€åŒ–å†³ç­–çŸ©é˜µï¼ˆBUILD/WATCH/DROPï¼‰
5. âœ… è¯é•¿åº¦é™åˆ¶ï¼ˆ3-8è¯ï¼‰
6. âœ… æç®€è®¾è®¡ï¼ˆå•æ–‡ä»¶ï¼Œå¿«é€Ÿæ‰§è¡Œï¼‰

+ æˆ‘ä»¬çš„ä¼˜åŠ¿ï¼š
7. âœ… é•¿å°¾è¯ä¼˜å…ˆ
8. âœ… AIå¯è§£å†³ç­›é€‰
9. âœ… ç²¾ç¾HTMLæŠ¥å‘Š

è¿è¡Œæ—¶é—´ï¼šçº¦10-15åˆ†é’Ÿï¼ˆvs 1å°æ—¶æ·±åº¦ç‰ˆï¼‰
é€‚ç”¨åœºæ™¯ï¼šå¿«é€Ÿæµ‹è¯•ã€æ—¥å¸¸ç›‘æ§

ä½œè€…ï¼šAI Profit Hunter Team
ç‰ˆæœ¬ï¼š4.0 Lite (èåˆç‰ˆ)
æ—¥æœŸï¼š2026-01-31
"""

import os
import sys
import time
import re
import requests
import pandas as pd
from datetime import datetime
from typing import List, Dict, Set
from pytrends.request import TrendReq
import warnings
warnings.filterwarnings('ignore')

# ==================== é…ç½®åŒº ====================

SEED_WORDS_FILE = "words.md"
DATA_DIR = "data"
REPORTS_DIR = os.path.join(DATA_DIR, "reports")

# Benchmark åŸºå‡†å…³é”®è¯ï¼ˆæ¥è‡ª Yuanbaoï¼‰
BENCHMARK_KEYWORD = "GPTs"
MIN_RATIO = 0.05  # æœ€ä½çƒ­åº¦æ¯”å€¼ï¼š5%
TIMEFRAME = "now 7-d"

# è¯é•¿åº¦é™åˆ¶ï¼ˆæ¥è‡ª Yuanbaoï¼‰
MIN_WORDS = 3
MAX_WORDS = 8

# å¼±ç«äº‰å¯¹æ‰‹åŸŸåï¼ˆæ¥è‡ª Yuanbaoï¼Œæ‰©å±•ç‰ˆï¼‰
WEAK_COMPETITORS = [
    'reddit.com', 'quora.com', 'medium.com', 'stackoverflow.com',
    'github.com', 'dev.to', 'indiehackers.com', 'linkedin.com',
    'twitter.com', 'facebook.com', 'pinterest.com'
]

# æ„å›¾è¯„åˆ†æƒé‡ï¼ˆæ¥è‡ª Yuanbaoï¼‰
INTENT_WEIGHTS = {
    "pain": 3,        # ç—›ç‚¹ä¿¡å·æƒé‡æœ€é«˜
    "tool": 2,        # å•†ä¸šå·¥å…·æ„å›¾
    "comparison": 2   # ç«äº‰å¯¹æ¯”
}

# ç—›ç‚¹ä¿¡å·è¯åº“ï¼ˆæ‰©å±•ç‰ˆï¼‰
PAIN_TRIGGERS = [
    "struggling with", "can't", "cannot", "fix", "solve", "error",
    "slow", "manual", "tedious", "hard to", "alternative to",
    "how to", "problem", "issue", "help", "need", "frustrated",
    "annoying", "difficult", "broken", "not working"
]

# å•†ä¸šå·¥å…·ä¿¡å·ï¼ˆæ‰©å±•ç‰ˆï¼‰
COMMERCIAL_TRIGGERS = [
    "tool", "app", "generator", "calculator", "converter",
    "maker", "builder", "checker", "editor", "analyzer",
    "tracker", "finder", "downloader", "optimizer", "creator"
]

# ==================== å·¥å…·å‡½æ•° ====================

def log_execution(message: str, level: str = "INFO"):
    """æ—¥å¿—è®°å½•"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")

def ensure_dirs():
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(REPORTS_DIR, exist_ok=True)

def load_seed_words(filepath: str = SEED_WORDS_FILE) -> List[str]:
    """åŠ è½½ç§å­è¯"""
    if not os.path.exists(filepath):
        log_execution(f"âš ï¸ {filepath} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ç§å­è¯", "WARNING")
        return ["calculator", "generator", "converter"]
    
    seeds = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('åºå·'):
                continue
            
            # æå–å…³é”®è¯
            if '\t' in line:
                parts = line.split('\t')
                if len(parts) >= 2:
                    word = parts[1].strip()
                    match = re.match(r'([A-Za-z]+)', word)
                    if match:
                        seeds.append(match.group(1).lower())
    
    seeds = list(dict.fromkeys(seeds))
    log_execution(f"âœ… åŠ è½½äº† {len(seeds)} ä¸ªç§å­è¯")
    return seeds[:5]  # é™åˆ¶ä¸º5ä¸ªç§å­è¯ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰

# ==================== Step 1: Google Autocomplete æŒ–æ˜ ====================

def google_suggest(query: str, gl: str = "us") -> List[str]:
    """è°ƒç”¨ Google Autocomplete API"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "client": "firefox",
        "q": query,
        "hl": "en",
        "gl": gl
    }
    
    try:
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json()
        return data[1] if len(data) > 1 else []
    except Exception as e:
        log_execution(f"Suggest å¤±è´¥ '{query}': {str(e)[:50]}", "WARNING")
        return []

def mine_keywords(seeds: List[str]) -> List[str]:
    """æŒ–æ˜å…³é”®è¯ï¼ˆAlphabet Soup ç­–ç•¥ï¼‰"""
    log_execution(f"ğŸ” Step 1: æŒ–æ˜å…³é”®è¯ï¼ˆ{len(seeds)} ä¸ªç§å­è¯ï¼‰")
    
    all_keywords = set()
    
    for idx, seed in enumerate(seeds, 1):
        log_execution(f"  [{idx}/{len(seeds)}] æŒ–æ˜: {seed}")
        
        # åŸºç¡€æŸ¥è¯¢
        all_keywords.update(google_suggest(seed))
        time.sleep(0.5)
        
        # åç¼€ç©ºæ ¼
        all_keywords.update(google_suggest(f"{seed} "))
        time.sleep(0.5)
        
        # Alphabet Soupï¼ˆé‡‡æ ·ï¼šæ¯éš”ä¸€ä¸ªå­—æ¯ï¼‰
        for char in "abcdefghijklmnopqrstuvwxyz"[::2]:
            all_keywords.update(google_suggest(f"{seed} {char}"))
            time.sleep(0.3)
        
        log_execution(f"  âœ… {seed}: ç´¯è®¡ {len(all_keywords)} ä¸ªå€™é€‰è¯")
    
    return list(all_keywords)

# ==================== Step 2: æ„å›¾è¯„åˆ†ä¸ç­›é€‰ ====================

def calculate_intent_score(keyword: str) -> Dict:
    """
    è®¡ç®—æ„å›¾è¯„åˆ†ï¼ˆå€Ÿé‰´ Yuanbao çš„åŠ æƒç³»ç»Ÿï¼‰
    
    è¯„åˆ†è§„åˆ™ï¼š
    - ç—›ç‚¹ä¿¡å·ï¼š+3åˆ†
    - å•†ä¸šå·¥å…·ï¼š+2åˆ†
    - ç«äº‰å¯¹æ¯”ï¼š+2åˆ†
    
    é€šè¿‡æ ‡å‡†ï¼šâ‰¥2åˆ†
    """
    kw_lower = keyword.lower()
    intent_score = 0
    signals = []
    
    # ç—›ç‚¹ä¿¡å·ï¼ˆæƒé‡æœ€é«˜ï¼‰
    if any(p in kw_lower for p in PAIN_TRIGGERS):
        intent_score += INTENT_WEIGHTS["pain"]
        signals.append("Pain")
    
    # å•†ä¸šå·¥å…·æ„å›¾
    if any(c in kw_lower for c in COMMERCIAL_TRIGGERS):
        intent_score += INTENT_WEIGHTS["tool"]
        signals.append("Tool")
    
    # ç«äº‰å¯¹æ¯”æ„å›¾
    if " vs " in kw_lower or "alternative" in kw_lower or "instead of" in kw_lower:
        intent_score += INTENT_WEIGHTS["comparison"]
        signals.append("Comparison")
    
    return {
        "intent_score": intent_score,
        "signals": signals,
        "is_high_intent": intent_score >= 2
    }

def filter_candidates(keywords: List[str]) -> List[Dict]:
    """
    ç­›é€‰å€™é€‰è¯
    
    ç­›é€‰æ¡ä»¶ï¼š
    1. è¯é•¿åº¦ï¼š3-8 è¯ï¼ˆæ¥è‡ª Yuanbaoï¼‰
    2. æ„å›¾è¯„åˆ†ï¼šâ‰¥2åˆ†
    3. é•¿å°¾è¯ä¼˜å…ˆ
    4. AIå¯è§£å†³ï¼ˆéå®ç‰©äº§å“ï¼‰
    """
    log_execution(f"ğŸ” Step 2: ç­›é€‰å€™é€‰è¯ï¼ˆä» {len(keywords)} ä¸ªä¸­ç­›é€‰ï¼‰")
    
    candidates = []
    
    # æ’é™¤å®ç‰©äº§å“çš„å…³é”®è¯
    physical_products = [
        "maker 20", "ice maker", "coffee maker", "bread maker",
        "generator 20", "diesel generator", "honda generator",
        "phone", "laptop", "camera", "printer", "tablet"
    ]
    
    for kw in keywords:
        kw_lower = kw.lower()
        words = kw_lower.split()
        
        # æ¡ä»¶1: è¯é•¿åº¦é™åˆ¶ï¼ˆ3-8è¯ï¼‰
        if not (MIN_WORDS <= len(words) <= MAX_WORDS):
            continue
        
        # æ¡ä»¶2: æ’é™¤å®ç‰©äº§å“
        if any(pp in kw_lower for pp in physical_products):
            continue
        
        # æ¡ä»¶3: è®¡ç®—æ„å›¾è¯„åˆ†
        intent_data = calculate_intent_score(kw)
        
        if intent_data["is_high_intent"]:
            candidates.append({
                "keyword": kw,
                "word_count": len(words),
                "intent_score": intent_data["intent_score"],
                "signals": ", ".join(intent_data["signals"])
            })
    
    # æŒ‰æ„å›¾è¯„åˆ†æ’åº
    candidates.sort(key=lambda x: x["intent_score"], reverse=True)
    
    log_execution(f"âœ… ç­›é€‰å‡º {len(candidates)} ä¸ªé«˜æ„å›¾å€™é€‰è¯")
    return candidates

# ==================== Step 3: GPTs Benchmark å¯¹æ¯” ====================

def benchmark_against_gpts(candidates: List[Dict], max_check: int = 20) -> List[Dict]:
    """
    ç”¨ "GPTs" ä½œä¸ºåŸºå‡†ï¼Œå¯¹æ¯”å…³é”®è¯çƒ­åº¦ï¼ˆæ¥è‡ª Yuanbaoï¼‰
    
    åªä¿ç•™çƒ­åº¦ â‰¥ 5% GPTs çš„è¯
    """
    log_execution(f"ğŸ” Step 3: GPTs Benchmark å¯¹æ¯”ï¼ˆæ£€æŸ¥ Top {max_check} ä¸ªï¼‰")
    
    verified = []
    
    try:
        pytrends = TrendReq(hl='en-US', tz=360, retries=2, backoff_factor=0.5)
    except Exception as e:
        log_execution(f"âš ï¸ Trends åˆå§‹åŒ–å¤±è´¥: {e}", "WARNING")
        return candidates[:max_check]
    
    for idx, item in enumerate(candidates[:max_check], 1):
        kw = item["keyword"]
        log_execution(f"  [{idx}/{max_check}] æ£€æŸ¥: {kw}")
        
        try:
            pytrends.build_payload([BENCHMARK_KEYWORD, kw], timeframe=TIMEFRAME)
            df = pytrends.interest_over_time()
            
            if not df.empty and BENCHMARK_KEYWORD in df.columns and kw in df.columns:
                avg_gpts = df[BENCHMARK_KEYWORD].mean()
                avg_kw = df[kw].mean()
                ratio = avg_kw / avg_gpts if avg_gpts > 0 else 0
                
                item["avg_gpts"] = avg_gpts
                item["avg_kw"] = avg_kw
                item["ratio"] = ratio
                item["ratio_pct"] = f"{ratio*100:.1f}%"
                
                # åªä¿ç•™ ratio â‰¥ 5% çš„è¯
                if ratio >= MIN_RATIO:
                    verified.append(item)
                    log_execution(f"    âœ… é€šè¿‡ï¼š{ratio*100:.1f}% vs GPTs")
                else:
                    log_execution(f"    âŒ è¿‡æ»¤ï¼š{ratio*100:.1f}% < 5%")
            
            time.sleep(2)  # ç¤¼è²Œå»¶è¿Ÿ
            
        except Exception as e:
            log_execution(f"    âš ï¸ é”™è¯¯: {str(e)[:50]}", "WARNING")
    
    log_execution(f"âœ… {len(verified)} ä¸ªå…³é”®è¯é€šè¿‡ GPTs Benchmark")
    return verified

# ==================== Step 4: DuckDuckGo SERP åˆ†æ ====================

def analyze_serp_ddg(keyword: str) -> Dict:
    """
    ç”¨ DuckDuckGo åˆ†æ SERPï¼ˆæ¥è‡ª Yuanbaoï¼Œè½»é‡çº§ï¼‰
    
    ä¼˜ç‚¹ï¼š
    - ä¸éœ€è¦ Playwright
    - ä¸ä¼šè¢« Google é™é¢‘
    - é€Ÿåº¦å¿«ï¼ˆ1-2ç§’/è¯ï¼‰
    """
    url = f"https://html.duckduckgo.com/html/?q={keyword}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    
    try:
        r = requests.get(url, headers=headers, timeout=10)
        
        if r.status_code == 200:
            # ç”¨ Regex æå–ç»“æœé“¾æ¥
            links = re.findall(r'class="result__a" href="([^"]+)"', r.text)
            
            domains = []
            for link in links[:5]:  # åªæ£€æŸ¥ Top 5
                try:
                    domain = link.split("/")[2].replace("www.", "")
                    domains.append(domain)
                except:
                    pass
            
            # æ£€æµ‹å¼±ç«äº‰å¯¹æ‰‹
            weak_spots = sum(1 for d in domains if any(w in d for w in WEAK_COMPETITORS))
            
            # å†³ç­–çŸ©é˜µï¼ˆæ¥è‡ª Yuanbaoï¼‰
            if weak_spots >= 2:
                competition = "ğŸŸ¢ LOW"
                decision = "BUILD NOW"
            elif weak_spots == 1:
                competition = "ğŸŸ¡ MED"
                decision = "WATCH"
            else:
                competition = "ğŸ”´ HIGH"
                decision = "DROP"
            
            return {
                "top_domains": domains,
                "weak_spots": weak_spots,
                "competition": competition,
                "decision": decision,
                "has_gap": weak_spots >= 2
            }
        else:
            return {"error": f"HTTP {r.status_code}"}
            
    except Exception as e:
        return {"error": str(e)}

def analyze_serp_batch(candidates: List[Dict]) -> List[Dict]:
    """æ‰¹é‡ SERP åˆ†æ"""
    log_execution(f"ğŸ” Step 4: SERP ç«äº‰åˆ†æï¼ˆ{len(candidates)} ä¸ªå…³é”®è¯ï¼‰")
    
    for idx, item in enumerate(candidates, 1):
        kw = item["keyword"]
        log_execution(f"  [{idx}/{len(candidates)}] åˆ†æ: {kw}")
        
        serp_data = analyze_serp_ddg(kw)
        
        if "error" not in serp_data:
            item.update(serp_data)
            log_execution(f"    {serp_data['competition']} - {serp_data['decision']}")
        else:
            item["competition"] = "âšª UNKNOWN"
            item["decision"] = "SKIP"
            log_execution(f"    âš ï¸ é”™è¯¯: {serp_data['error'][:30]}", "WARNING")
        
        time.sleep(1.5)  # ç¤¼è²Œå»¶è¿Ÿ
    
    return candidates

# ==================== Step 5: ç”ŸæˆæŠ¥å‘Š ====================

def generate_html_report(results: List[Dict]) -> str:
    """ç”Ÿæˆç²¾ç¾çš„HTMLæŠ¥å‘Š"""
    # æŒ‰å†³ç­–æ’åºï¼šBUILD NOW > WATCH > DROP
    results.sort(key=lambda x: (
        x.get("decision") == "BUILD NOW",
        x.get("decision") == "WATCH",
        x.get("ratio", 0)
    ), reverse=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = os.path.join(REPORTS_DIR, f"profit_hunter_lite_{timestamp}.html")
    
    # ç»Ÿè®¡
    build_now = sum(1 for r in results if r.get("decision") == "BUILD NOW")
    watch = sum(1 for r in results if r.get("decision") == "WATCH")
    drop = sum(1 for r in results if r.get("decision") == "DROP")
    avg_ratio = sum(r.get("ratio", 0) for r in results) / len(results) if results else 0
    
    html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Profit Hunter Lite Report - {timestamp}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.6;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
        }}
        .content {{
            padding: 40px;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        .stat-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            text-align: center;
        }}
        .stat-number {{
            font-size: 2.5em;
            font-weight: bold;
        }}
        .result-item {{
            background: #f8f9fa;
            padding: 20px;
            margin-bottom: 15px;
            border-radius: 10px;
            border-left: 5px solid #667eea;
        }}
        .keyword {{
            font-size: 1.3em;
            font-weight: bold;
            color: #333;
            margin-bottom: 10px;
        }}
        .build-now {{ border-left-color: #28a745; }}
        .watch {{ border-left-color: #ffc107; }}
        .drop {{ border-left-color: #dc3545; }}
        .tag {{
            display: inline-block;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            margin-right: 8px;
            margin-bottom: 5px;
        }}
        .tag-build {{ background: #28a745; color: white; }}
        .tag-watch {{ background: #ffc107; color: #333; }}
        .tag-drop {{ background: #dc3545; color: white; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ Profit Hunter Lite Report</h1>
            <p>è½»é‡çº§å¿«é€Ÿç‰ˆ - èåˆ Yuanbao Skills ä¼˜ç‚¹</p>
            <p style="opacity: 0.8; margin-top: 10px;">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        </div>
        
        <div class="content">
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-number">{len(results)}</div>
                    <div>æ€»å€™é€‰è¯</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{build_now}</div>
                    <div>ğŸŸ¢ BUILD NOW</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{watch}</div>
                    <div>ğŸŸ¡ WATCH</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{drop}</div>
                    <div>ğŸ”´ DROP</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{avg_ratio*100:.1f}%</div>
                    <div>å¹³å‡çƒ­åº¦ vs GPTs</div>
                </div>
            </div>
            
            <h2 style="margin-bottom: 20px; border-bottom: 3px solid #667eea; padding-bottom: 10px;">
                ğŸ“Š åˆ†æç»“æœ
            </h2>
"""
    
    for idx, item in enumerate(results, 1):
        decision = item.get("decision", "SKIP")
        css_class = "build-now" if "BUILD" in decision else ("watch" if "WATCH" in decision else "drop")
        tag_class = "tag-build" if "BUILD" in decision else ("tag-watch" if "WATCH" in decision else "tag-drop")
        
        html_content += f"""
            <div class="result-item {css_class}">
                <div class="keyword">{idx}. {item['keyword']}</div>
                <div>
                    <span class="tag {tag_class}">{decision}</span>
                    <span class="tag" style="background: #e9ecef; color: #333;">{item.get('competition', 'N/A')}</span>
                    <span class="tag" style="background: #e7f3ff; color: #2196F3;">
                        çƒ­åº¦: {item.get('ratio_pct', 'N/A')}
                    </span>
                    <span class="tag" style="background: #fff3cd; color: #856404;">
                        æ„å›¾åˆ†: {item['intent_score']}åˆ†
                    </span>
                </div>
                <div style="margin-top: 10px; font-size: 0.9em; color: #666;">
                    <strong>ä¿¡å·:</strong> {item['signals']} | 
                    <strong>å¼±ç«äº‰å¯¹æ‰‹:</strong> {item.get('weak_spots', 0)} | 
                    <strong>TopåŸŸå:</strong> {', '.join(item.get('top_domains', [])[:3])}
                </div>
            </div>
"""
    
    html_content += """
        </div>
    </div>
</body>
</html>
"""
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    log_execution(f"ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    return filename

# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    ensure_dirs()
    
    log_execution("\n" + "="*60)
    log_execution("ğŸš€ Profit Hunter LITE - è½»é‡çº§å¿«é€Ÿç‰ˆ")
    log_execution("èåˆ Yuanbao Skills + æˆ‘ä»¬çš„ä¼˜åŠ¿")
    log_execution("="*60 + "\n")
    
    # Step 1: åŠ è½½ç§å­è¯
    seeds = load_seed_words()
    
    # Step 2: æŒ–æ˜å…³é”®è¯
    raw_keywords = mine_keywords(seeds)
    log_execution(f"âœ… Step 1 å®Œæˆï¼šæŒ–æ˜äº† {len(raw_keywords)} ä¸ªå…³é”®è¯")
    
    # Step 3: ç­›é€‰å€™é€‰è¯
    candidates = filter_candidates(raw_keywords)
    log_execution(f"âœ… Step 2 å®Œæˆï¼šç­›é€‰å‡º {len(candidates)} ä¸ªå€™é€‰è¯")
    
    # Step 4: GPTs Benchmark å¯¹æ¯”
    verified = benchmark_against_gpts(candidates, max_check=20)
    log_execution(f"âœ… Step 3 å®Œæˆï¼š{len(verified)} ä¸ªé€šè¿‡ Benchmark")
    
    # Step 5: SERP ç«äº‰åˆ†æ
    final_results = analyze_serp_batch(verified)
    log_execution(f"âœ… Step 4 å®Œæˆï¼šSERP åˆ†æå®Œæˆ")
    
    # Step 6: ç”ŸæˆæŠ¥å‘Š
    report_path = generate_html_report(final_results)
    
    # è¾“å‡ºç»“æœ
    log_execution("\n" + "="*60)
    log_execution("ğŸ è¿è¡Œå®Œæˆï¼")
    log_execution("="*60)
    
    print("\nğŸ“Š Top 10 ç»“æœï¼š")
    for idx, item in enumerate(final_results[:10], 1):
        print(f"\n{idx}. {item['keyword']}")
        print(f"   å†³ç­–: {item.get('decision', 'N/A')}")
        print(f"   ç«äº‰: {item.get('competition', 'N/A')}")
        print(f"   çƒ­åº¦: {item.get('ratio_pct', 'N/A')} vs GPTs")
        print(f"   æ„å›¾: {item['signals']}")
    
    print(f"\nğŸ“„ å®Œæ•´æŠ¥å‘Š: {report_path}")

if __name__ == "__main__":
    main()

---
name: trend-breakout-hunter
description: "Daily Google Trends breakout keyword discovery for AI tool sites. Scans seed words against Google Trends Rising/Breakout queries, filters for tool-buildable opportunities, and outputs an actionable candidate list. Use when: 'find breakout keywords', 'today's trending terms', 'scan Google Trends', 'new tool opportunities', 'rising queries', or '/hunt-trends' command. Primary method: pytrends API. Fallback: browser automation."
license: MIT
---

# Trend Breakout Hunter

## SILENT EXECUTION PROTOCOL

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  MANDATORY RULES - NO EXCEPTIONS                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  1. DO NOT ask "Should I continue?" - just execute            â•‘
â•‘  2. DO NOT ask for missing parameters - use defaults          â•‘
â•‘  3. DO NOT output partial results - complete in one response  â•‘
â•‘  4. If pytrends fails â†’ switch to browser fallback silently   â•‘
â•‘  5. If a seed word returns nothing â†’ skip it, continue        â•‘
â•‘  6. Generate FULL candidate list in ONE atomic response       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Overview

This skill executes a daily workflow:

```
ç§å­è¯è¡¨ (47 words.md)
       â†“
Google Trends â†’ Related Queries â†’ Rising/Breakout
       â†“
è‡ªåŠ¨è¿‡æ»¤ï¼ˆå»å™ªå£°ã€å»æ–°é—»ã€å»äººåï¼‰
       â†“
å·¥å…·åŒ–åˆ¤æ–­ï¼ˆèƒ½å¦åšæˆ calculator/generator/checkerï¼Ÿï¼‰
       â†“
è¾“å‡ºï¼šAI å·¥å…·ç«™å€™é€‰è¯æ¸…å•
```

---

## Execution Pipeline

### Step 0: Google Autocomplete Mining (Foundation Layer)

**æ ¸å¿ƒåŸç†**ï¼šä» words.md çš„æ¯ä¸ªç§å­è¯å‡ºå‘ï¼Œç”¨ Google Suggest æ¥å£æŒ–æ˜çœŸå®ç”¨æˆ·æœç´¢è¯ç»„ã€‚

```
âš ï¸ é‡è¦ï¼šGoogle Suggest â‰  Google Trends
   - Suggest = å®æ—¶ç”¨æˆ·è¾“å…¥è¡Œä¸ºä¿¡å·ï¼ˆæ›´æ—©ã€æ›´çœŸå®ï¼‰
   - Trends = ç»Ÿè®¡åçš„æœç´¢é‡è¶‹åŠ¿ï¼ˆæœ‰å»¶è¿Ÿï¼‰
   - ä¸¤è€…ç»“åˆ = æ—¢æŒ–éœ€æ±‚ï¼ŒåˆéªŒçƒ­åº¦
```

**API æ¥å£ï¼ˆéå®˜æ–¹ä½†æç¨³ï¼‰**ï¼š

```
https://suggestqueries.google.com/complete/search?client=firefox&q={query}&hl=en&gl=us
```

**è¿”å›æ ¼å¼**ï¼š
```json
[
  "calculator",
  ["calculator", "calculator app", "calculator online", "calculator scientific", "calculator date"]
]
```

**ä¸‰ç§æŒ–è¯æ¨¡å¼ï¼ˆAlphabet Soup æŠ€æœ¯ï¼‰**ï¼š

| æ¨¡å¼ | æŸ¥è¯¢ç¤ºä¾‹ | æŒ–æ˜ç›®æ ‡ |
|------|----------|----------|
| **è¯åœ¨å‰** | `calculator` | åŸºç¡€è”æƒ³ |
| **è¯åœ¨å‰+ç©ºæ ¼** | `calculator ` | åç¼€æ‰©å±• |
| **è¯åœ¨åï¼ˆa-zæšä¸¾ï¼‰** | `a calculator`, `b calculator`... | å‰ç¼€æ‰©å±• |
| **ç»„åˆè¯** | `dating calculator` | åœºæ™¯åŒ–æ‰©å±• |

**Google Suggest Code**ï¼š

```python
import requests
import time

def google_suggest(query, hl="en", gl="us"):
    """è·å– Google æœç´¢è”æƒ³è¯"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "client": "firefox",
        "q": query,
        "hl": hl,
        "gl": gl
    }
    try:
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        return r.json()[1]
    except Exception as e:
        print(f"Suggest failed for '{query}': {e}")
        return []

def alphabet_soup_mining(seed_word, hl="en", gl="us"):
    """Alphabet Soup å…¨é‡æŒ–è¯"""
    results = set()

    # 1ï¸âƒ£ åŸºç¡€æŸ¥è¯¢ï¼šcalculator
    results.update(google_suggest(seed_word, hl, gl))
    time.sleep(0.5)

    # 2ï¸âƒ£ åç¼€æ‰©å±•ï¼šcalculator _
    results.update(google_suggest(f"{seed_word} ", hl, gl))
    time.sleep(0.5)

    # 3ï¸âƒ£ å‰ç¼€æ‰©å±•ï¼ša-z + calculator
    for c in "abcdefghijklmnopqrstuvwxyz":
        suggestions = google_suggest(f"{c} {seed_word}", hl, gl)
        results.update(suggestions)
        time.sleep(0.3)  # é™ä½é™é¢‘é£é™©

    # 4ï¸âƒ£ æ•°å­—å‰ç¼€ï¼š0-9 + calculator
    for n in "0123456789":
        suggestions = google_suggest(f"{n} {seed_word}", hl, gl)
        results.update(suggestions)
        time.sleep(0.3)

    return list(results)

# ç¤ºä¾‹ï¼šæŒ–æ˜ calculator ç›¸å…³è¯
seed = "calculator"
all_suggestions = alphabet_soup_mining(seed)

# è¿‡æ»¤ï¼šåªä¿ç•™åŒ…å«ç§å­è¯çš„ç»“æœ
tool_keywords = [s for s in all_suggestions if seed in s.lower()]
print(f"Found {len(tool_keywords)} tool keywords for '{seed}'")
for kw in sorted(tool_keywords):
    print(f"  - {kw}")
```

**æ‰¹é‡å¤„ç†æ‰€æœ‰ç§å­è¯**ï¼š

```python
import pandas as pd

# ä» words.md åŠ è½½ç§å­è¯
seed_words = [
    "calculator", "generator", "converter", "maker", "checker",
    "editor", "builder", "analyzer", "optimizer", "tracker"
    # ... åŠ è½½å…¨éƒ¨ 47 ä¸ª
]

all_keywords = []

for seed in seed_words:
    print(f"Mining: {seed}")
    suggestions = alphabet_soup_mining(seed)

    for s in suggestions:
        all_keywords.append({
            "seed": seed,
            "keyword": s,
            "word_count": len(s.split()),
            "source": "google_suggest"
        })

    time.sleep(2)  # æ¯ä¸ªç§å­è¯ä¹‹é—´æš‚åœ

# ä¿å­˜ç»“æœ
df = pd.DataFrame(all_keywords)
df.to_csv("suggest_keywords.csv", index=False)
print(f"Total keywords mined: {len(df)}")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

| seed | keyword | word_count |
|------|---------|------------|
| calculator | age calculator | 2 |
| calculator | bmi calculator | 2 |
| calculator | love calculator | 2 |
| calculator | pregnancy due date calculator | 4 |
| generator | ai image generator | 3 |
| generator | qr code generator | 3 |

---

### Step 1: Harvest Rising/Breakout Terms

```python
from pytrends.request import TrendReq

pytrends = TrendReq(hl='en-US', tz=360)
pytrends.build_payload([seed_word], timeframe='now 7-d')
related = pytrends.related_queries()
rising_queries = related[seed_word]['rising']
# Look for: "Breakout" label OR growth > 100%
```

### Step 2: Benchmark Comparison (CRITICAL âš ï¸)

**æ ¸å¿ƒåŸç†**ï¼šæŠŠæ¯ä¸ªæ–°è¯å’ŒåŸºå‡†è¯ "GPTs" æ”¾åœ¨**åŒä¸€ä¸ª payload** é‡Œå¯¹æ¯”ã€‚

```
âš ï¸ é‡è¦ï¼šGoogle Trends çš„æ•°å€¼æ˜¯"ç›¸å¯¹å€¼ 0-100"
   - åŒä¸€ä¸ª payload é‡Œçš„è¯å…±äº«åŒä¸€ä¸ªæ ‡å°ºï¼Œæ‰èƒ½æ¯”è¾ƒ
   - åˆ†å¼€æŸ¥è¯¢çš„æ•°å€¼ä¸å¯æ¯”ï¼ˆæ ‡å°ºä¸åŒï¼‰
```

**Benchmark Code**:

```python
from pytrends.request import TrendReq
import pandas as pd
import time

pytrends = TrendReq(hl='en-US', tz=480, retries=2, backoff_factor=0.2)

def compare_to_gpts(term, timeframe="now 7-d", geo="", gprop=""):
    """Compare any term against 'GPTs' as benchmark"""
    kw_list = [term, "GPTs"]  # å…³é”®ï¼šåŒä¸€ä¸ª payload é‡Œå¯¹æ¯”
    pytrends.build_payload(kw_list, timeframe=timeframe, geo=geo, gprop=gprop)

    df = pytrends.interest_over_time()
    if df is None or df.empty:
        return None

    if "isPartial" in df.columns:
        df = df.drop(columns=["isPartial"])

    term_series = df[term]
    gpts_series = df["GPTs"]

    term_avg = float(term_series.mean())
    gpts_avg = float(gpts_series.mean())

    # çƒ­åº¦æ¯”å€¼ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
    ratio = (term_avg / gpts_avg) if gpts_avg > 0 else None

    # å¢é•¿é€Ÿåº¦ï¼ˆé¦–å°¾å·®ï¼‰
    term_growth = float(term_series.iloc[-1] - term_series.iloc[0])
    gpts_growth = float(gpts_series.iloc[-1] - gpts_series.iloc[0])
    growth_ratio = (term_growth / gpts_growth) if gpts_growth != 0 else None

    return {
        "term": term,
        "term_avg": term_avg,
        "gpts_avg": gpts_avg,
        "avg_ratio": ratio,           # termçƒ­åº¦ / GPTsçƒ­åº¦
        "term_growth": term_growth,
        "gpts_growth": gpts_growth,
        "growth_ratio": growth_ratio, # termå¢é€Ÿ / GPTså¢é€Ÿ
    }

# æ‰¹é‡å¯¹æ¯”
terms = ["aura calculator", "heic converter", "prompt optimizer"]
results = []
for t in terms:
    r = compare_to_gpts(t, timeframe="now 7-d")
    if r:
        results.append(r)
    time.sleep(4)  # é™ä½é™é¢‘é£é™©

out = pd.DataFrame(results).sort_values("avg_ratio", ascending=False)
print(out)
```

---

## Benchmark Decision Thresholds

| avg_ratio | term_growth | Decision | Meaning |
|-----------|-------------|----------|---------|
| **â‰¥ 0.3** | > 0 | ğŸ”´ **ç«‹å³åš** | çƒ­åº¦æ¥è¿‘ GPTsï¼Œä¸”åœ¨æ¶¨ |
| **0.1 - 0.3** | > 0 | ğŸŸ¡ **é‡ç‚¹è§‚å¯Ÿ** | ä¸­ç­‰çƒ­åº¦ï¼Œæœ‰å¢é•¿åŠ¿å¤´ |
| **0.05 - 0.1** | > 5 | ğŸŸ¢ **æ—©æœŸçº¢åˆ©** | å°ä¼—ä½†æ¶¨é€Ÿå¿«ï¼ŒæŠ¢å…ˆæœº |
| **< 0.05** | â‰¤ 0 | âŒ **ä¸¢å¼ƒ** | æ—¢ä¸çƒ­ä¹Ÿä¸æ¶¨ |

**ç®€åŒ–è§„åˆ™**ï¼š
```
IF avg_ratio >= 0.3 AND term_growth > 0 â†’ âœ… BUILD
IF avg_ratio >= 0.05 AND term_growth > 5 â†’ ğŸ‘€ WATCH
ELSE â†’ âŒ DROP
```

---

## Fallback: Browser Automation (Detailed)

When pytrends fails (rate limit, 429 error, empty response), **silently switch** to browser automation.

### Trigger Conditions

```
Switch to browser fallback when:
- pytrends returns None or empty DataFrame
- HTTP 429 (Too Many Requests)
- Connection timeout after 2 retries
- "ResponseError" or "TooManyRequestsError"
```

### Browser Automation Workflow

**Step 1: Navigate to Google Trends**

```
URL Pattern: https://trends.google.com/trends/explore?q={seed_word}&date=now%207-d&geo=US

Example:
https://trends.google.com/trends/explore?q=calculator&date=now%207-d&geo=US
```

**Step 2: Wait for Page Load**

```
Wait for selector: div[class*="related-queries"]
Timeout: 10 seconds
If timeout â†’ log error, skip this seed word, continue
```

**Step 3: Switch to "Rising" Tab**

```
Click selector: button[aria-label="Rising"]
   OR: div[class*="rising"]
   OR: text="Rising"

Wait 2 seconds for data refresh
```

**Step 4: Extract Rising Queries Table**

```
Target table: div[class*="related-queries"] table

For each row:
  - Column 1: Query text (the keyword)
  - Column 2: Growth value ("Breakout" or "+X%")

Store as:
{
  "query": "aura calculator",
  "growth": "Breakout",  // or "+450%"
  "seed": "calculator"
}
```

**Step 5: Screenshot for Verification (Optional)**

```
Save screenshot to: ./screenshots/{seed_word}_{YYYYMMDD}.png
Purpose: Debug validation, historical record
```

**Step 6: Benchmark Comparison (Same as pytrends)**

```
For each extracted query:
  Navigate to: https://trends.google.com/trends/explore?q={query},GPTs&date=now%207-d

  Extract both trend lines
  Calculate avg_ratio = query_avg / gpts_avg
  Apply same decision thresholds
```

### Browser Automation Code Example

```python
# Using Playwright (recommended for agent-browser)
from playwright.sync_api import sync_playwright
import time

def browser_harvest_rising(seed_word, headless=True):
    """Fallback: Extract rising queries via browser automation"""

    results = []
    url = f"https://trends.google.com/trends/explore?q={seed_word}&date=now%207-d&geo=US"

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=headless)
        page = browser.new_page()

        try:
            # Step 1: Navigate
            page.goto(url, timeout=15000)

            # Step 2: Wait for related queries section
            page.wait_for_selector('div[class*="related-queries"]', timeout=10000)
            time.sleep(2)  # Let JS render

            # Step 3: Click "Rising" tab
            rising_btn = page.query_selector('button:has-text("Rising")')
            if rising_btn:
                rising_btn.click()
                time.sleep(2)

            # Step 4: Extract table rows
            rows = page.query_selector_all('div[class*="related-queries"] table tr')

            for row in rows[1:]:  # Skip header
                cells = row.query_selector_all('td')
                if len(cells) >= 2:
                    query = cells[0].inner_text().strip()
                    growth = cells[1].inner_text().strip()

                    results.append({
                        "query": query,
                        "growth": growth,
                        "seed": seed_word,
                        "source": "browser"
                    })

            # Step 5: Screenshot (optional)
            page.screenshot(path=f"./screenshots/{seed_word}_{time.strftime('%Y%m%d')}.png")

        except Exception as e:
            print(f"Browser fallback failed for {seed_word}: {e}")

        finally:
            browser.close()

    return results

def browser_compare_to_gpts(term, headless=True):
    """Fallback: Compare term vs GPTs via browser"""

    url = f"https://trends.google.com/trends/explore?q={term},GPTs&date=now%207-d&geo=US"

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=headless)
        page = browser.new_page()

        try:
            page.goto(url, timeout=15000)
            page.wait_for_selector('div[class*="interest-over-time"]', timeout=10000)
            time.sleep(3)

            # Extract trend values from chart (simplified)
            # In practice, you'd parse the SVG or use accessibility labels

            # Screenshot for manual verification
            page.screenshot(path=f"./screenshots/compare_{term}_vs_GPTs.png")

            # Return placeholder - real impl would parse chart data
            return {
                "term": term,
                "comparison_screenshot": f"./screenshots/compare_{term}_vs_GPTs.png",
                "source": "browser"
            }

        except Exception as e:
            print(f"Browser comparison failed for {term}: {e}")
            return None

        finally:
            browser.close()
```

### Error Handling Matrix

| Error | Action | Log |
|-------|--------|-----|
| Page timeout | Skip seed, continue | `âš ï¸ {seed}: page timeout` |
| No rising tab | Use "Top" queries instead | `â„¹ï¸ {seed}: no rising, using top` |
| Empty table | Skip seed, continue | `âš ï¸ {seed}: no rising queries` |
| CAPTCHA detected | Pause 60s, retry once | `ğŸ”„ {seed}: captcha, retrying` |
| Browser crash | Restart browser, continue | `ğŸ”„ Browser restarted` |

### Rate Limiting Best Practices

```
Browser automation rate limits:
- Wait 5-10 seconds between seed words
- Max 20 queries per session
- Rotate user agents if needed
- Use residential proxy for scale

Example pacing:
for seed in seed_words:
    results = browser_harvest_rising(seed)
    time.sleep(random.uniform(5, 10))  # Random delay
```

### When to Use Browser vs pytrends

| Scenario | Use |
|----------|-----|
| Daily batch (10-50 seeds) | pytrends first |
| pytrends 429 error | Switch to browser |
| Need visual verification | Browser + screenshot |
| Debugging discrepancies | Browser to confirm |
| pytrends data looks wrong | Browser as ground truth |

---

## Auto-Update words.md (New Root Words)

**æ¯æ¬¡è¿è¡Œåï¼Œè‡ªåŠ¨å°†æ–°å‘ç°çš„è¯æ ¹æ·»åŠ åˆ° words.md**

```python
import re
from datetime import datetime

def extract_new_roots(candidates):
    """ä»å€™é€‰è¯ä¸­è¯†åˆ«æ–°è¯æ ¹"""
    # å·²çŸ¥è¯æ ¹åˆ—è¡¨ï¼ˆä» words.md åŠ è½½ï¼‰
    known_roots = load_known_roots()

    # æ½œåœ¨æ–°è¯æ ¹æ¨¡å¼
    root_patterns = [
        r'(\w+er)$',      # cloner, humanizer, upscaler
        r'(\w+or)$',      # predictor, generator
        r'(\w+izer)$',    # summarizer, optimizer
        r'(\w+ator)$',    # calculator, translator
    ]

    new_roots = {}

    for c in candidates:
        keyword = c.get('keyword', '').lower()
        words = keyword.split()

        for word in words:
            for pattern in root_patterns:
                match = re.search(pattern, word)
                if match:
                    potential_root = word.capitalize()
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°è¯æ ¹
                    if potential_root.lower() not in [r.lower() for r in known_roots]:
                        if potential_root not in new_roots:
                            new_roots[potential_root] = {
                                "example": keyword,
                                "count": 1
                            }
                        else:
                            new_roots[potential_root]["count"] += 1

    # åªä¿ç•™å‡ºç° 2 æ¬¡ä»¥ä¸Šçš„æ–°è¯æ ¹
    return {k: v for k, v in new_roots.items() if v["count"] >= 2}

def load_known_roots():
    """ä» words.md åŠ è½½å·²çŸ¥è¯æ ¹"""
    known_roots = []
    try:
        with open("words.md", "r", encoding="utf-8") as f:
            for line in f:
                # æå–ç¬¬äºŒåˆ—ï¼ˆåç§°ï¼‰
                parts = line.strip().split("\t")
                if len(parts) >= 2 and parts[0].isdigit():
                    # æå–è¯æ ¹åï¼ˆå»æ‰ä¸­æ–‡æ³¨é‡Šï¼‰
                    root_name = parts[1].split("ï¼ˆ")[0].strip()
                    known_roots.append(root_name)
    except FileNotFoundError:
        pass
    return known_roots

def append_new_roots_to_words_md(new_roots):
    """å°†æ–°è¯æ ¹è‡ªåŠ¨è¿½åŠ åˆ° words.md"""
    if not new_roots:
        print("â„¹ï¸ No new roots to add")
        return []

    added_roots = []

    # è¯»å–ç°æœ‰å†…å®¹ï¼Œè·å–æœ€å¤§åºå·
    try:
        with open("words.md", "r", encoding="utf-8") as f:
            lines = f.readlines()

        # æ‰¾åˆ°æœ€å¤§åºå·
        max_num = 0
        for line in lines:
            parts = line.strip().split("\t")
            if parts and parts[0].isdigit():
                max_num = max(max_num, int(parts[0]))
    except FileNotFoundError:
        lines = ["åºå·\tåç§°\tç”¨æˆ·éœ€æ±‚\tå¸¸è§æ­é…\n"]
        max_num = 0

    # è¿½åŠ æ–°è¯æ ¹
    with open("words.md", "a", encoding="utf-8") as f:
        for root, info in new_roots.items():
            max_num += 1
            # ç”Ÿæˆç”¨æˆ·éœ€æ±‚æè¿°
            need_desc = f"ç”¨æˆ·æœç´¢ {root} ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚"
            # ç”Ÿæˆå¸¸è§æ­é…
            example = info["example"]
            common_use = f"AI {root}, Online {root}, Free {root}"

            new_line = f"{max_num}\t{root}ï¼ˆ{root.lower()}ï¼‰\t{need_desc}\t{common_use}\n"
            f.write(new_line)
            added_roots.append(root)
            print(f"âœ… Added new root: {root} (example: {example})")

    return added_roots

def run_daily_hunt_with_auto_update():
    """æ¯æ—¥çŒè¯ä¸»æµç¨‹ï¼ˆå«è‡ªåŠ¨æ›´æ–° words.mdï¼‰"""

    # ... å‰é¢çš„æ­¥éª¤ä¿æŒä¸å˜ ...

    # Step 0-4: æ‰§è¡Œå…³é”®è¯çŒå–
    qualified = execute_hunt_pipeline()

    # Step 5: ç”Ÿæˆ HTML æŠ¥å‘Š
    report_file = generate_html_report(qualified, stats, execution_notes)

    # Step 6: è‡ªåŠ¨æ›´æ–° words.md â¬…ï¸ æ–°å¢
    new_roots = extract_new_roots(qualified)
    if new_roots:
        added = append_new_roots_to_words_md(new_roots)
        print(f"\nğŸ“ Auto-added {len(added)} new roots to words.md:")
        for root in added:
            print(f"   - {root}")

    return report_file, qualified, new_roots
```

**æ–°è¯æ ¹è¯†åˆ«è§„åˆ™**ï¼š

| æ¨¡å¼ | ç¤ºä¾‹ | è¯´æ˜ |
|------|------|------|
| `*er` | Cloner, Upscaler | åŠ¨ä½œæ‰§è¡Œè€… |
| `*or` | Predictor, Processor | æ‰§è¡Œå™¨ç±» |
| `*izer` | Summarizer, Humanizer | è½¬åŒ–å·¥å…· |
| `*ator` | Calculator, Translator | è®¡ç®—/ç¿»è¯‘ç±» |

**æ·»åŠ æ¡ä»¶**ï¼š
```
1. åŒ¹é…è¯æ ¹æ¨¡å¼ï¼ˆ*er, *or, *izer, *atorï¼‰
2. åœ¨å€™é€‰è¯ä¸­å‡ºç° â‰¥ 2 æ¬¡
3. ä¸åœ¨ç°æœ‰ words.md ä¸­
```

**words.md æ›´æ–°ç¤ºä¾‹**ï¼š

```
# è‡ªåŠ¨è¿½åŠ çš„æ–°è¯æ ¹ï¼ˆ2025-01-28ï¼‰
48	Clonerï¼ˆclonerï¼‰	ç”¨æˆ·æœç´¢ Cloner ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚	AI Cloner, Online Cloner, Free Cloner
49	Humanizerï¼ˆhumanizerï¼‰	ç”¨æˆ·æœç´¢ Humanizer ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚	AI Humanizer, Online Humanizer, Free Humanizer
50	Upscalerï¼ˆupscalerï¼‰	ç”¨æˆ·æœç´¢ Upscaler ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚	AI Upscaler, Online Upscaler, Free Upscaler
51	Predictorï¼ˆpredictorï¼‰	ç”¨æˆ·æœç´¢ Predictor ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚	AI Predictor, Online Predictor, Free Predictor
52	Summarizerï¼ˆsummarizerï¼‰	ç”¨æˆ·æœç´¢ Summarizer ç›¸å…³å·¥å…·æˆ–åŠŸèƒ½ã€‚	AI Summarizer, Online Summarizer, Free Summarizer
```

---

## Seed Word Categories

Load from `words.md` (47 root words):

| Category | Words | Tool Potential |
|----------|-------|----------------|
| **Generators** | Generator, Maker, Creator, Builder | â­â­â­â­â­ |
| **Converters** | Converter, Convert, Translator, Format | â­â­â­â­â­ |
| **Calculators** | Calculator, Estimator, Evaluator | â­â­â­â­â­ |
| **Checkers** | Checker, Detector, Verifier, Analyzer | â­â­â­â­ |
| **Editors** | Editor, Processor, Optimizer | â­â­â­â­ |
| **Managers** | Manager, Planner, Scheduler, Tracker | â­â­â­ |
| **Viewers** | Viewer, Explorer, Monitor, Dashboard | â­â­â­ |
| **Others** | Downloader, Uploader, Extractor, Scraper | â­â­â­ |

---

## Auto-Filter Rules (Critical)

### âœ… KEEP - High Value Signals

```
Contains ANY of:
  - calculator, generator, maker, converter, checker
  - ai, tool, online, free
  - how to, best, vs

AND meets:
  - Growth: "Breakout" OR > 100%
  - Word count: 2-5 words (not too short, not too long)
  - Has clear noun (not just adjectives)
```

### âŒ DROP - Noise Signals

```
Auto-reject if:
  - Person name (celebrity, politician, athlete)
  - Geographic name only (city, country)
  - News event (election, disaster, scandal)
  - Single word with no context
  - Contains: death, scandal, lawsuit, arrest
  - Entertainment only: movie, song, album, episode
```

### âš ï¸ REVIEW - Edge Cases

```
Flag for human review if:
  - Gaming terms (could be simulator opportunity)
  - Brand names (could be "X alternative" opportunity)
  - Ambiguous intent
```

---

## Tool-Buildability Assessment

For each surviving keyword, score 1-5:

| Score | Criteria | Example |
|-------|----------|---------|
| 5 | Direct tool match (X + root word) | "aura calculator" |
| 4 | Implied tool need (how to X) | "how to convert heic" |
| 3 | Possible tool (needs validation) | "ai voice clone" |
| 2 | Weak tool signal | "best ai apps" |
| 1 | No tool intent | "what is chatgpt" |

**Threshold**: Only include score â‰¥ 3

---

## SERP Competition Quick Check

For high-potential keywords, assess SERP:

| SERP Pattern | Competition | Action |
|--------------|-------------|--------|
| All blogs/articles | ğŸŸ¢ Low | Build immediately |
| Mix of tools + blogs | ğŸŸ¡ Medium | Build with differentiation |
| Big tech tools dominate | ğŸ”´ High | Skip or niche down |
| Empty/thin results | ğŸŸ¢ Very Low | First mover advantage |

---

## Output Format

### HTML Report Generation (MANDATORY)

**æ¯æ¬¡è¿è¡Œå¿…é¡»ç”Ÿæˆ HTML æŠ¥å‘Šï¼Œä¿å­˜åˆ° `data/` æ–‡ä»¶å¤¹**

```
æ–‡ä»¶å‘½åè§„åˆ™ï¼š
data/keyword_report_{YYYYMMDD}_{HHMMSS}.html

ç¤ºä¾‹ï¼š
data/keyword_report_20250128_143052.html
```

**HTML æŠ¥å‘Šç”Ÿæˆä»£ç **ï¼š

```python
import os
from datetime import datetime

def generate_html_report(candidates, stats, execution_notes):
    """ç”Ÿæˆ HTML åˆ†ææŠ¥å‘Š"""

    # ç¡®ä¿ data æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs("data", exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå«æ—¥æœŸæ—¶é—´ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"data/keyword_report_{timestamp}.html"

    # æ„å»º HTML å†…å®¹
    html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¯ Trend Breakout Report - {datetime.now().strftime("%Y-%m-%d %H:%M")}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            padding: 2rem;
        }}
        .container {{ max-width: 1400px; margin: 0 auto; }}
        h1 {{
            font-size: 2.5rem;
            margin-bottom: 1rem;
            background: linear-gradient(90deg, #00d9ff, #00ff88);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }}
        .stat-card {{
            background: rgba(255,255,255,0.1);
            border-radius: 12px;
            padding: 1.5rem;
            text-align: center;
            backdrop-filter: blur(10px);
        }}
        .stat-card .number {{ font-size: 2.5rem; font-weight: bold; color: #00d9ff; }}
        .stat-card .label {{ color: #aaa; margin-top: 0.5rem; }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
            background: rgba(255,255,255,0.05);
            border-radius: 12px;
            overflow: hidden;
        }}
        th, td {{ padding: 1rem; text-align: left; border-bottom: 1px solid rgba(255,255,255,0.1); }}
        th {{ background: rgba(0,217,255,0.2); font-weight: 600; }}
        tr:hover {{ background: rgba(255,255,255,0.05); }}
        .priority-high {{ color: #ff6b6b; font-weight: bold; }}
        .priority-medium {{ color: #ffd93d; }}
        .priority-low {{ color: #6bcb77; }}
        .growth-breakout {{
            background: linear-gradient(90deg, #ff6b6b, #ff8e53);
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-size: 0.85rem;
        }}
        .section {{ margin: 3rem 0; }}
        .section h2 {{
            font-size: 1.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid rgba(0,217,255,0.3);
        }}
        .top-actions {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1rem;
        }}
        .action-card {{
            background: linear-gradient(135deg, rgba(0,217,255,0.2), rgba(0,255,136,0.1));
            border-radius: 12px;
            padding: 1.5rem;
            border-left: 4px solid #00d9ff;
        }}
        .action-card h3 {{ color: #00d9ff; margin-bottom: 0.5rem; }}
        .notes {{
            background: rgba(255,255,255,0.05);
            border-radius: 12px;
            padding: 1.5rem;
            font-family: monospace;
        }}
        .footer {{
            text-align: center;
            margin-top: 3rem;
            color: #666;
            font-size: 0.9rem;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ Trend Breakout Report</h1>
        <p style="color:#aaa;">Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>

        <!-- Stats Cards -->
        <div class="stats">
            <div class="stat-card">
                <div class="number">{stats['seeds_scanned']}</div>
                <div class="label">Seeds Scanned</div>
            </div>
            <div class="stat-card">
                <div class="number">{stats['rising_found']}</div>
                <div class="label">Rising Terms Found</div>
            </div>
            <div class="stat-card">
                <div class="number">{stats['after_filter']}</div>
                <div class="label">After Filtering</div>
            </div>
            <div class="stat-card">
                <div class="number">{stats['qualified']}</div>
                <div class="label">Qualified Candidates</div>
            </div>
        </div>

        <!-- Main Table -->
        <div class="section">
            <h2>ğŸ“Š AI Tool Site Candidates</h2>
            <table>
                <thead>
                    <tr>
                        <th>Keyword</th>
                        <th>Seed</th>
                        <th>Growth</th>
                        <th>GPTs Ratio</th>
                        <th>Tool Type</th>
                        <th>Buildability</th>
                        <th>Competition</th>
                        <th>Decision</th>
                    </tr>
                </thead>
                <tbody>
                    {"".join(generate_table_rows(candidates))}
                </tbody>
            </table>
        </div>

        <!-- Top 5 Actions -->
        <div class="section">
            <h2>ğŸ”¥ Top 5 Immediate Actions</h2>
            <div class="top-actions">
                {"".join(generate_action_cards(candidates[:5]))}
            </div>
        </div>

        <!-- Execution Notes -->
        <div class="section">
            <h2>âš ï¸ Execution Notes</h2>
            <div class="notes">
                <p><strong>Method:</strong> {execution_notes['method']}</p>
                <p><strong>Seeds Skipped:</strong> {execution_notes.get('skipped', 'None')}</p>
                <p><strong>Errors:</strong> {execution_notes.get('errors', 'None')}</p>
            </div>
        </div>

        <div class="footer">
            Generated by Trend Breakout Hunter Skill | {datetime.now().strftime("%Y-%m-%d")}
        </div>
    </div>
</body>
</html>"""

    # ä¿å­˜æ–‡ä»¶
    with open(filename, "w", encoding="utf-8") as f:
        f.write(html_content)

    print(f"âœ… Report saved: {filename}")
    return filename

def generate_table_rows(candidates):
    """ç”Ÿæˆè¡¨æ ¼è¡Œ HTML"""
    rows = []
    for c in candidates:
        growth_class = "growth-breakout" if "Breakout" in str(c.get('growth', '')) else ""
        priority_class = {
            "Build": "priority-high",
            "Watch": "priority-medium",
            "Drop": "priority-low"
        }.get(c.get('decision', '').replace('âœ…', '').replace('ğŸ‘€', '').replace('âŒ', '').strip(), "")

        rows.append(f"""
            <tr>
                <td><strong>{c.get('keyword', '')}</strong></td>
                <td>{c.get('seed', '')}</td>
                <td><span class="{growth_class}">{c.get('growth', 'N/A')}</span></td>
                <td>{c.get('avg_ratio', 'N/A')}</td>
                <td>{c.get('tool_type', '')}</td>
                <td>{c.get('buildability', '')}/5</td>
                <td>{c.get('competition', '')}</td>
                <td class="{priority_class}">{c.get('decision', '')}</td>
            </tr>
        """)
    return rows

def generate_action_cards(top_candidates):
    """ç”Ÿæˆ Top Actions å¡ç‰‡ HTML"""
    cards = []
    for i, c in enumerate(top_candidates, 1):
        cards.append(f"""
            <div class="action-card">
                <h3>#{i} {c.get('keyword', '')}</h3>
                <p><strong>Growth:</strong> {c.get('growth', 'N/A')}</p>
                <p><strong>Ratio vs GPTs:</strong> {c.get('avg_ratio', 'N/A')}</p>
                <p><strong>Why:</strong> {c.get('reason', 'High potential opportunity')}</p>
            </div>
        """)
    return cards
```

**å®Œæ•´æ‰§è¡Œæµç¨‹ï¼ˆå«æŠ¥å‘Šç”Ÿæˆï¼‰**ï¼š

```python
def run_daily_hunt():
    """æ¯æ—¥å…³é”®è¯çŒå–ä¸»æµç¨‹"""
    from datetime import datetime

    # Step 0: Google Suggest æŒ–è¯
    all_suggestions = []
    for seed in seed_words:
        suggestions = alphabet_soup_mining(seed)
        all_suggestions.extend(suggestions)

    # Step 1: Google Trends Rising/Breakout
    rising_terms = harvest_rising_terms(seed_words)

    # Step 2: GPTs Benchmark å¯¹æ¯”
    candidates = []
    for term in rising_terms:
        result = compare_to_gpts(term['query'])
        if result:
            candidates.append({**term, **result})

    # Step 3: è¿‡æ»¤ + è¯„åˆ†
    qualified = filter_and_score(candidates)

    # Step 4: æ’åºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    qualified.sort(key=lambda x: (
        x.get('decision', '') == 'âœ…Build',
        x.get('avg_ratio', 0)
    ), reverse=True)

    # Step 5: ç”Ÿæˆ HTML æŠ¥å‘Š â¬…ï¸ å¿…é¡»æ‰§è¡Œ
    stats = {
        "seeds_scanned": len(seed_words),
        "rising_found": len(rising_terms),
        "after_filter": len(candidates),
        "qualified": len(qualified)
    }
    execution_notes = {
        "method": "pytrends (primary)",
        "skipped": "None",
        "errors": "None"
    }

    report_file = generate_html_report(qualified, stats, execution_notes)

    # åŒæ—¶è¾“å‡º Markdown åˆ°æ§åˆ¶å°
    print_markdown_summary(qualified)

    return report_file, qualified

# è¿è¡Œ
if __name__ == "__main__":
    report_file, results = run_daily_hunt()
    print(f"\nğŸ‰ Done! Report: {report_file}")
```

**æŠ¥å‘Šæ–‡ä»¶ç»“æ„**ï¼š

```
data/
â”œâ”€â”€ keyword_report_20250128_143052.html
â”œâ”€â”€ keyword_report_20250129_091530.html
â”œâ”€â”€ keyword_report_20250130_083015.html
â””â”€â”€ ...
```

---

### Candidate List Table

```markdown
# ğŸ¯ Trend Breakout Report

> **Date**: {YYYY-MM-DD}
> **Seeds Scanned**: {count}/47
> **Rising Terms Found**: {count}
> **After Filtering**: {count}
> **Qualified Candidates**: {count}

---

## ğŸ“Š AI Tool Site Candidates

| Keyword | Seed | Growth | Tool Type | Buildability | Competition | Decision |
|---------|------|--------|-----------|--------------|-------------|----------|
| {term} | {root} | ğŸš€Breakout / +X% | calc/gen/check/conv | 1-5 | Low/Med/High | âœ…Build / ğŸ‘€Watch / âŒDrop |

---

## ğŸ”¥ Top 5 Immediate Actions

1. **{keyword}** - {reason why it's #1}
2. ...

---

## ğŸ“ New Root Words Discovered

| New Root | Example Usage | Add to words.md? |
|----------|---------------|------------------|
| {word} | {example} | Yes/No |

---

## âš ï¸ Execution Notes

- Method used: pytrends / browser fallback
- Seeds skipped: {list if any}
- Errors encountered: {list if any}
```

---

## Database Schema (For Long-term Storage)

Store results for historical tracking:

```sql
CREATE TABLE trend_candidates (
  id INTEGER PRIMARY KEY,
  date DATE NOT NULL,
  seed_term VARCHAR(50),
  trend_term VARCHAR(100),
  growth_type VARCHAR(20),  -- 'breakout' or percentage
  growth_value INTEGER,     -- null for breakout, number for %
  tool_type VARCHAR(20),    -- calculator/generator/checker/converter/other
  buildability_score INTEGER CHECK (buildability_score BETWEEN 1 AND 5),
  competition VARCHAR(10),  -- low/medium/high
  decision VARCHAR(10),     -- build/watch/drop
  notes TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Recommended**: Export to CSV daily, import to Notion/Airtable weekly

---

## Example Execution

### Input
```
User: å¸®æˆ‘è·‘ä¸€ä¸‹ä»Šå¤©çš„è¶‹åŠ¿è¯
```

### Correct Output (Abbreviated)

```markdown
# ğŸ¯ Trend Breakout Report

> **Date**: 2025-01-28
> **Seeds Scanned**: 47/47
> **Rising Terms Found**: 312
> **After Filtering**: 89
> **Qualified Candidates**: 23

---

## ğŸ“Š AI Tool Site Candidates

| Keyword | Seed | Growth | Tool Type | Buildability | Competition | Decision |
|---------|------|--------|-----------|--------------|-------------|----------|
| aura points calculator | Calculator | ğŸš€Breakout | calculator | 5 | Low | âœ…Build |
| heic to jpg converter | Converter | +450% | converter | 5 | Medium | âœ…Build |
| ai voice generator free | Generator | +280% | generator | 5 | High | ğŸ‘€Watch |
| prompt optimizer tool | Optimizer | +190% | optimizer | 4 | Low | âœ…Build |
| deepseek vs chatgpt | Comparator | ğŸš€Breakout | comparator | 4 | Medium | âœ…Build |

---

## ğŸ”¥ Top 5 Immediate Actions

1. **aura points calculator** - TikTok viral, zero competition, simple build
2. **heic to jpg converter** - Evergreen need, existing tools are clunky
3. **prompt optimizer tool** - AI workflow essential, low competition
4. **deepseek vs chatgpt** - Hot topic, comparison page opportunity
5. **n8n template generator** - Automation trend, developer audience

---

## ğŸ“ New Root Words Discovered

| New Root | Example Usage | Add to words.md? |
|----------|---------------|------------------|
| Cloner | voice cloner, style cloner | Yes |
| Humanizer | ai humanizer, text humanizer | Yes |

---

## âš ï¸ Execution Notes

- Method used: pytrends (primary)
- Seeds skipped: None
- Errors encountered: None
```

---

## Anti-Patterns (FORBIDDEN)

```
âŒ "æˆ‘æ‰¾åˆ°äº†ä¸€äº›è¯ï¼Œä½ æƒ³çœ‹å“ªäº›ï¼Ÿ"
   â†’ å¿…é¡»ä¸€æ¬¡æ€§è¾“å‡ºå…¨éƒ¨

âŒ "pytrends æŠ¥é”™äº†ï¼Œæ€ä¹ˆåŠï¼Ÿ"
   â†’ é™é»˜åˆ‡æ¢åˆ° browser fallback

âŒ "è¿™ä¸ªè¯æˆ‘ä¸ç¡®å®šï¼Œä½ è§‰å¾—å‘¢ï¼Ÿ"
   â†’ ç”¨è¯„åˆ†ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­ï¼Œä¸è¦é—®

âŒ "éœ€è¦æˆ‘ç»§ç»­æ‰«æå‰©ä¸‹çš„ç§å­è¯å—ï¼Ÿ"
   â†’ å¿…é¡»æ‰«æå…¨éƒ¨ï¼Œä¸€æ¬¡å®Œæˆ

âŒ "è¾“å‡ºå¤ªé•¿äº†ï¼Œè¦åˆ†æ‰¹å—ï¼Ÿ"
   â†’ ä¸åˆ†æ‰¹ï¼Œå®Œæ•´è¾“å‡º
```

---

## Integration with Other Skills

After running this skill:

| Next Step | Use Skill | Purpose |
|-----------|-----------|---------|
| Validate content angle | `content-strategy` | Confirm topic worth writing |
| Scale to multiple pages | `programmatic-seo` | Template-based page generation |
| Build comparison pages | `competitor-alternatives` | "X vs Y" or "X alternative" pages |
| Add structured data | `schema-markup` | Rich snippets for SERP |
| Track performance | `analytics-tracking` | Monitor organic traffic |

---

## Limitations

- pytrends is unofficial; may hit rate limits (solution: add delays, use proxies)
- "Breakout" threshold is Google's black box (solution: also track high % growth)
- Some trends are noise (solution: auto-filter rules above)
- SERP check is manual (solution: integrate SerpAPI for automation)

---

## Quick Commands

| Command | Action |
|---------|--------|
| `/hunt-trends` | Run full scan with all 47 seeds |
| `/hunt-trends calculator` | Scan only "calculator" related |
| `/hunt-trends --top10` | Output only top 10 candidates |
| `/hunt-trends --export csv` | Output in CSV format |
